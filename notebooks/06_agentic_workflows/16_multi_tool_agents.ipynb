{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Notebook 16: Agentic Workflows - Multi-Tool MCP Agents\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Build complex multi-tool agents\n",
    "- Implement agent planning and reflection\n",
    "- Chain tools for sophisticated workflows\n",
    "- Compare agent architectures (ReAct, Plan-and-Execute)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "### Hardware Requirements\n",
    "\n",
    "| Model Option | Model Name | Size | Min RAM | Recommended Setup | Notes |\n",
    "|--------------|------------|------|---------|-------------------|-------|\n",
    "| **small (CPU-friendly)** | llama3.2:3b | 2GB | 8GB | 8GB RAM, CPU | Better reasoning than 1b |\n",
    "| **large (GPU-optimized)** | llama3.1:8b | 4.7GB | 16GB | 12GB VRAM (RTX 4080) | Multi-step planning |\n",
    "| **SOTA (reference only)** | Claude 3.5 Sonnet | API | N/A | API key required | Best-in-class reasoning |\n",
    "\n",
    "### Software Requirements\n",
    "- Python 3.10+\n",
    "- Completed Notebooks 14-15\n",
    "- Libraries: `mcp`, `ollama`, `requests`\n",
    "\n",
    "### Installation\n",
    "\n",
    "```bash\n",
    "pip install mcp ollama requests\n",
    "ollama pull llama3.2:3b\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## Agent Architectures\n",
    "\n",
    "### 1. ReAct (Reason + Act)\n",
    "- **Think** → **Act** → **Observe** → Repeat\n",
    "- LLM reasons about what to do, takes action, observes result\n",
    "- Most common pattern, used in Notebooks 14-15\n",
    "\n",
    "### 2. Plan-and-Execute\n",
    "- **Plan** all steps upfront → **Execute** sequentially\n",
    "- Better for complex multi-step tasks\n",
    "- Can replan if steps fail\n",
    "\n",
    "### 3. Reflection\n",
    "- **Act** → **Reflect** on results → **Improve**\n",
    "- Self-critique and refinement\n",
    "- Good for quality-critical tasks\n",
    "\n",
    "### Comparison\n",
    "\n",
    "| Architecture | Best For | Iterations | Token Cost |\n",
    "|--------------|----------|------------|------------|\n",
    "| **ReAct** | Simple tasks | 2-5 | Low |\n",
    "| **Plan-and-Execute** | Complex workflows | 5-15 | Medium |\n",
    "| **Reflection** | Quality tasks | 3-10 | High |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## Expected Behaviors\n",
    "\n",
    "### Multi-Tool Workflows\n",
    "- Agent uses 5-10 different tools in one task\n",
    "- Tool calls ordered logically\n",
    "- Results from one tool inform next tool choice\n",
    "\n",
    "### Planning Phase\n",
    "```\n",
    "Planning...\n",
    "Step 1: Search for information\n",
    "Step 2: Calculate statistics\n",
    "Step 3: Write report\n",
    "Step 4: Save to file\n",
    "```\n",
    "\n",
    "### Reflection Phase\n",
    "```\n",
    "Reflection: Result looks incomplete\n",
    "Improvement: Gather more data\n",
    "Retry with better approach...\n",
    "```\n",
    "\n",
    "### Performance\n",
    "- **llama3.2:3b**: 3-7 seconds per tool call\n",
    "- **llama3.1:8b**: 2-4 seconds per tool call\n",
    "- Complex tasks: 30-120 seconds total\n",
    "\n",
    "### Common Observations\n",
    "- Larger models plan more effectively\n",
    "- Tool ordering improves with experience\n",
    "- Reflection loops can get stuck (set max iterations)\n",
    "- Clear task descriptions yield better plans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": "import json\nimport random\nimport requests\nfrom typing import List, Dict, Any\nimport ollama\nfrom pathlib import Path\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Set seed for reproducibility\nrandom.seed(1103)\n\nprint(\"Multi-Tool Agent Tutorial - Setup Complete\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHOOSE YOUR MODEL:\n",
    "\n",
    "# Option 1: small model (better reasoning than 1b)\n",
    "MODEL_NAME = \"llama3.2:3b\"  # 2GB\n",
    "\n",
    "# Option 2: large model (best for complex planning)\n",
    "# MODEL_NAME = \"llama3.1:8b\"  # 4.7GB\n",
    "\n",
    "print(f\"Selected model: {MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Building a Comprehensive Tool Set\n",
    "\n",
    "Let's create a rich set of tools for complex workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComprehensiveToolServer:\n",
    "    \"\"\"Server with tools for research, calculation, file ops, and web access.\"\"\"\n",
    "    \n",
    "    def __init__(self, workspace: str = \"./agent_workspace\"):\n",
    "        self.workspace = Path(workspace)\n",
    "        self.workspace.mkdir(exist_ok=True)\n",
    "        \n",
    "        self.tools = [\n",
    "            # Web & Search Tools\n",
    "            {\n",
    "                'type': 'function',\n",
    "                'function': {\n",
    "                    'name': 'web_search',\n",
    "                    'description': 'Search the web for information (mock data)',\n",
    "                    'parameters': {\n",
    "                        'type': 'object',\n",
    "                        'properties': {\n",
    "                            'query': {'type': 'string', 'description': 'Search query'}\n",
    "                        },\n",
    "                        'required': ['query']\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            # Calculation Tools\n",
    "            {\n",
    "                'type': 'function',\n",
    "                'function': {\n",
    "                    'name': 'calculate',\n",
    "                    'description': 'Evaluate mathematical expressions',\n",
    "                    'parameters': {\n",
    "                        'type': 'object',\n",
    "                        'properties': {\n",
    "                            'expression': {'type': 'string', 'description': 'Math expression to evaluate'}\n",
    "                        },\n",
    "                        'required': ['expression']\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                'type': 'function',\n",
    "                'function': {\n",
    "                    'name': 'statistics',\n",
    "                    'description': 'Calculate statistics (mean, median, std dev) for numbers',\n",
    "                    'parameters': {\n",
    "                        'type': 'object',\n",
    "                        'properties': {\n",
    "                            'numbers': {'type': 'array', 'items': {'type': 'number'}}\n",
    "                        },\n",
    "                        'required': ['numbers']\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            # File Operations\n",
    "            {\n",
    "                'type': 'function',\n",
    "                'function': {\n",
    "                    'name': 'save_report',\n",
    "                    'description': 'Save a report to a file',\n",
    "                    'parameters': {\n",
    "                        'type': 'object',\n",
    "                        'properties': {\n",
    "                            'filename': {'type': 'string'},\n",
    "                            'content': {'type': 'string'}\n",
    "                        },\n",
    "                        'required': ['filename', 'content']\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                'type': 'function',\n",
    "                'function': {\n",
    "                    'name': 'read_report',\n",
    "                    'description': 'Read a previously saved report',\n",
    "                    'parameters': {\n",
    "                        'type': 'object',\n",
    "                        'properties': {\n",
    "                            'filename': {'type': 'string'}\n",
    "                        },\n",
    "                        'required': ['filename']\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            # Data Processing\n",
    "            {\n",
    "                'type': 'function',\n",
    "                'function': {\n",
    "                    'name': 'summarize_text',\n",
    "                    'description': 'Summarize long text into key points',\n",
    "                    'parameters': {\n",
    "                        'type': 'object',\n",
    "                        'properties': {\n",
    "                            'text': {'type': 'string'},\n",
    "                            'max_points': {'type': 'integer', 'description': 'Max bullet points (default 5)'}\n",
    "                        },\n",
    "                        'required': ['text']\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            # Date/Time\n",
    "            {\n",
    "                'type': 'function',\n",
    "                'function': {\n",
    "                    'name': 'get_current_time',\n",
    "                    'description': 'Get current date and time',\n",
    "                    'parameters': {'type': 'object', 'properties': {}, 'required': []}\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        self.function_map = {\n",
    "            'web_search': self.web_search,\n",
    "            'calculate': self.calculate,\n",
    "            'statistics': self.statistics,\n",
    "            'save_report': self.save_report,\n",
    "            'read_report': self.read_report,\n",
    "            'summarize_text': self.summarize_text,\n",
    "            'get_current_time': self.get_current_time\n",
    "        }\n",
    "        \n",
    "        print(f\"ComprehensiveToolServer initialized\")\n",
    "        print(f\"Workspace: {self.workspace.absolute()}\")\n",
    "        print(f\"Available tools: {len(self.tools)}\")\n",
    "    \n",
    "    def web_search(self, query: str) -> str:\n",
    "        \"\"\"Mock web search.\"\"\"\n",
    "        mock_results = {\n",
    "            'python': 'Python is a high-level programming language. Created by Guido van Rossum in 1991.',\n",
    "            'machine learning': 'Machine learning is a subset of AI. Popular frameworks include TensorFlow and PyTorch.',\n",
    "            'climate change': 'Global temperatures have risen 1.1°C since pre-industrial times. Main cause is greenhouse gases.',\n",
    "            'covid-19': 'COVID-19 is caused by SARS-CoV-2 virus. First detected in December 2019 in Wuhan, China.'\n",
    "        }\n",
    "        \n",
    "        query_lower = query.lower()\n",
    "        for key in mock_results:\n",
    "            if key in query_lower:\n",
    "                return f\"Search results for '{query}': {mock_results[key]}\"\n",
    "        \n",
    "        return f\"Search results for '{query}': General information available. Topic is widely discussed.\"\n",
    "    \n",
    "    def calculate(self, expression: str) -> str:\n",
    "        \"\"\"Safely evaluate math expressions.\"\"\"\n",
    "        try:\n",
    "            result = eval(expression, {\"__builtins__\": {}}, {})\n",
    "            return f\"{expression} = {result}\"\n",
    "        except Exception as e:\n",
    "            return f\"Error calculating '{expression}': {str(e)}\"\n",
    "    \n",
    "    def statistics(self, numbers: List[float]) -> str:\n",
    "        \"\"\"Calculate statistics.\"\"\"\n",
    "        if not numbers:\n",
    "            return \"Error: Empty list\"\n",
    "        \n",
    "        import statistics as stats\n",
    "        result = {\n",
    "            'count': len(numbers),\n",
    "            'mean': round(stats.mean(numbers), 2),\n",
    "            'median': stats.median(numbers),\n",
    "            'stdev': round(stats.stdev(numbers), 2) if len(numbers) > 1 else 0,\n",
    "            'min': min(numbers),\n",
    "            'max': max(numbers)\n",
    "        }\n",
    "        return json.dumps(result, indent=2)\n",
    "    \n",
    "    def save_report(self, filename: str, content: str) -> str:\n",
    "        \"\"\"Save report to file.\"\"\"\n",
    "        try:\n",
    "            path = self.workspace / filename\n",
    "            with open(path, 'w', encoding='utf-8') as f:\n",
    "                f.write(content)\n",
    "            return f\"Report saved to {filename} ({len(content)} characters)\"\n",
    "        except Exception as e:\n",
    "            return f\"Error saving report: {str(e)}\"\n",
    "    \n",
    "    def read_report(self, filename: str) -> str:\n",
    "        \"\"\"Read report from file.\"\"\"\n",
    "        try:\n",
    "            path = self.workspace / filename\n",
    "            if not path.exists():\n",
    "                return f\"Error: Report '{filename}' not found\"\n",
    "            with open(path, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "            return content\n",
    "        except Exception as e:\n",
    "            return f\"Error reading report: {str(e)}\"\n",
    "    \n",
    "    def summarize_text(self, text: str, max_points: int = 5) -> str:\n",
    "        \"\"\"Create bullet point summary.\"\"\"\n",
    "        sentences = text.split('. ')\n",
    "        key_points = sentences[:max_points]\n",
    "        summary = '\\n'.join(f\"- {point.strip()}\" for point in key_points if point.strip())\n",
    "        return f\"Summary ({max_points} points):\\n{summary}\"\n",
    "    \n",
    "    def get_current_time(self) -> str:\n",
    "        \"\"\"Get current date/time.\"\"\"\n",
    "        from datetime import datetime\n",
    "        now = datetime.now()\n",
    "        return f\"Current time: {now.strftime('%Y-%m-%d %H:%M:%S')}\"\n",
    "    \n",
    "    def execute_tool(self, tool_name: str, arguments: dict) -> str:\n",
    "        \"\"\"Execute a tool.\"\"\"\n",
    "        if tool_name not in self.function_map:\n",
    "            return f\"Error: Unknown tool '{tool_name}'\"\n",
    "        function = self.function_map[tool_name]\n",
    "        return function(**arguments)\n",
    "\n",
    "tool_server = ComprehensiveToolServer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## Pattern 1: ReAct Agent (from Notebook 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def react_agent(prompt: str, model: str = MODEL_NAME, max_iterations: int = 15) -> str:\n",
    "    \"\"\"\n",
    "    ReAct: Reason → Act → Observe loop.\n",
    "    \"\"\"\n",
    "    messages = [{'role': 'user', 'content': prompt}]\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"ReAct Agent\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Task: {prompt}\\n\")\n",
    "    \n",
    "    for iteration in range(1, max_iterations + 1):\n",
    "        response = ollama.chat(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            tools=tool_server.tools\n",
    "        )\n",
    "        \n",
    "        messages.append(response['message'])\n",
    "        \n",
    "        if not response['message'].get('tool_calls'):\n",
    "            print(f\"\\nIteration {iteration}: Final Answer\")\n",
    "            final_answer = response['message']['content']\n",
    "            print(f\"Result: {final_answer}\")\n",
    "            print(f\"\\n{'='*70}\\n\")\n",
    "            return final_answer\n",
    "        \n",
    "        print(f\"Iteration {iteration}:\")\n",
    "        for tool_call in response['message']['tool_calls']:\n",
    "            function_name = tool_call['function']['name']\n",
    "            function_args = tool_call['function']['arguments']\n",
    "            \n",
    "            print(f\"  Action: {function_name}({json.dumps(function_args, indent=4)})\")\n",
    "            \n",
    "            result = tool_server.execute_tool(function_name, function_args)\n",
    "            print(f\"  Result: {result[:100]}...\" if len(result) > 100 else f\"  Result: {result}\")\n",
    "            \n",
    "            messages.append({'role': 'tool', 'content': str(result)})\n",
    "        print()\n",
    "    \n",
    "    return \"Max iterations reached\"\n",
    "\n",
    "print(\"ReAct agent ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## Example: Research Report Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = react_agent(\n",
    "    \"\"\"Create a research report about machine learning:\n",
    "    1. Search for information about machine learning\n",
    "    2. Summarize the findings\n",
    "    3. Add the current date to the report\n",
    "    4. Save it to 'ml_report.txt'\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Pattern 2: Plan-and-Execute Agent\n",
    "\n",
    "First plan all steps, then execute them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plan_and_execute_agent(prompt: str, model: str = MODEL_NAME) -> str:\n",
    "    \"\"\"\n",
    "    Plan-and-Execute: Create plan first, then execute steps.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Plan-and-Execute Agent\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Task: {prompt}\\n\")\n",
    "    \n",
    "    # Phase 1: Planning\n",
    "    print(\"Phase 1: Planning\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    planning_prompt = f\"\"\"Create a step-by-step plan to accomplish this task: {prompt}\n",
    "    \n",
    "Available tools:\n",
    "- web_search: Search for information\n",
    "- calculate: Do math\n",
    "- statistics: Calculate stats\n",
    "- save_report: Save file\n",
    "- read_report: Read file\n",
    "- summarize_text: Summarize text\n",
    "- get_current_time: Get date/time\n",
    "\n",
    "List the plan as numbered steps. Be specific about which tool to use.\"\"\"\n",
    "    \n",
    "    plan_response = ollama.chat(\n",
    "        model=model,\n",
    "        messages=[{'role': 'user', 'content': planning_prompt}]\n",
    "    )\n",
    "    \n",
    "    plan = plan_response['message']['content']\n",
    "    print(f\"Plan:\\n{plan}\\n\")\n",
    "    \n",
    "    # Phase 2: Execution\n",
    "    print(\"Phase 2: Execution\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    execution_prompt = f\"\"\"Execute this plan step by step:\n",
    "\n",
    "{plan}\n",
    "\n",
    "Original task: {prompt}\n",
    "\n",
    "Use the available tools to complete each step.\"\"\"\n",
    "    \n",
    "    messages = [{'role': 'user', 'content': execution_prompt}]\n",
    "    \n",
    "    for iteration in range(15):\n",
    "        response = ollama.chat(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            tools=tool_server.tools\n",
    "        )\n",
    "        \n",
    "        messages.append(response['message'])\n",
    "        \n",
    "        if not response['message'].get('tool_calls'):\n",
    "            final_answer = response['message']['content']\n",
    "            print(f\"\\nCompleted: {final_answer}\")\n",
    "            print(f\"\\n{'='*70}\\n\")\n",
    "            return final_answer\n",
    "        \n",
    "        print(f\"\\nStep {iteration + 1}:\")\n",
    "        for tool_call in response['message']['tool_calls']:\n",
    "            function_name = tool_call['function']['name']\n",
    "            function_args = tool_call['function']['arguments']\n",
    "            \n",
    "            print(f\"  Tool: {function_name}\")\n",
    "            result = tool_server.execute_tool(function_name, function_args)\n",
    "            print(f\"  Result: {result[:80]}...\" if len(result) > 80 else f\"  Result: {result}\")\n",
    "            \n",
    "            messages.append({'role': 'tool', 'content': str(result)})\n",
    "    \n",
    "    return \"Max iterations reached\"\n",
    "\n",
    "print(\"Plan-and-Execute agent ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = plan_and_execute_agent(\n",
    "    \"\"\"Research Python programming and create a summary report:\n",
    "    1. Find information about Python\n",
    "    2. Summarize into 3 key points\n",
    "    3. Save to 'python_summary.txt'\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## Pattern 3: Reflection Agent\n",
    "\n",
    "Agent reflects on results and improves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reflection_agent(prompt: str, model: str = MODEL_NAME, max_reflections: int = 3) -> str:\n",
    "    \"\"\"\n",
    "    Reflection: Act → Reflect → Improve loop.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Reflection Agent\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Task: {prompt}\\n\")\n",
    "    \n",
    "    for reflection_round in range(max_reflections):\n",
    "        print(f\"\\nRound {reflection_round + 1}:\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        # Execute task\n",
    "        messages = [{'role': 'user', 'content': prompt}]\n",
    "        result = None\n",
    "        \n",
    "        for iteration in range(10):\n",
    "            response = ollama.chat(\n",
    "                model=model,\n",
    "                messages=messages,\n",
    "                tools=tool_server.tools\n",
    "            )\n",
    "            \n",
    "            messages.append(response['message'])\n",
    "            \n",
    "            if not response['message'].get('tool_calls'):\n",
    "                result = response['message']['content']\n",
    "                break\n",
    "            \n",
    "            for tool_call in response['message']['tool_calls']:\n",
    "                function_name = tool_call['function']['name']\n",
    "                function_args = tool_call['function']['arguments']\n",
    "                \n",
    "                tool_result = tool_server.execute_tool(function_name, function_args)\n",
    "                messages.append({'role': 'tool', 'content': str(tool_result)})\n",
    "        \n",
    "        print(f\"Result: {result}\")\n",
    "        \n",
    "        # Reflect on result\n",
    "        if reflection_round < max_reflections - 1:\n",
    "            reflection_prompt = f\"\"\"Reflect on this result: {result}\n",
    "            \n",
    "Is it complete and high quality? What could be improved?\n",
    "Answer with 'GOOD' if satisfactory, or suggest improvements.\"\"\"\n",
    "            \n",
    "            reflection = ollama.chat(\n",
    "                model=model,\n",
    "                messages=[{'role': 'user', 'content': reflection_prompt}]\n",
    "            )\n",
    "            \n",
    "            reflection_text = reflection['message']['content']\n",
    "            print(f\"\\nReflection: {reflection_text}\")\n",
    "            \n",
    "            if 'GOOD' in reflection_text.upper():\n",
    "                print(\"\\nSatisfactory result achieved!\")\n",
    "                break\n",
    "            \n",
    "            # Update prompt with reflection\n",
    "            prompt = f\"{prompt}\\n\\nPrevious attempt feedback: {reflection_text}\\nPlease improve.\"\n",
    "    \n",
    "    print(f\"\\n{'='*70}\\n\")\n",
    "    return result\n",
    "\n",
    "print(\"Reflection agent ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = reflection_agent(\n",
    "    \"Create a detailed report about climate change with statistics and save it to 'climate_report.txt'\",\n",
    "    max_reflections=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## Comparing Agent Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "test_task = \"Search for COVID-19 information and create a 2-sentence summary. Save it to 'covid_summary.txt'.\"\n",
    "\n",
    "print(\"\\nComparing Agent Patterns\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Test ReAct\n",
    "start = time.time()\n",
    "react_result = react_agent(test_task)\n",
    "react_time = time.time() - start\n",
    "\n",
    "print(f\"\\n\\nREACT Agent:\")\n",
    "print(f\"  Time: {react_time:.2f}s\")\n",
    "print(f\"  Result length: {len(react_result)} chars\")\n",
    "\n",
    "# Test Plan-and-Execute\n",
    "start = time.time()\n",
    "plan_result = plan_and_execute_agent(test_task)\n",
    "plan_time = time.time() - start\n",
    "\n",
    "print(f\"\\n\\nPLAN-AND-EXECUTE Agent:\")\n",
    "print(f\"  Time: {plan_time:.2f}s\")\n",
    "print(f\"  Result length: {len(plan_result)} chars\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\\nSummary:\")\n",
    "print(f\"  ReAct: {react_time:.2f}s\")\n",
    "print(f\"  Plan-and-Execute: {plan_time:.2f}s\")\n",
    "print(f\"  Winner: {'ReAct' if react_time < plan_time else 'Plan-and-Execute'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## Advanced: Tool Chaining\n",
    "\n",
    "Build workflows where one tool's output feeds into another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_task = \"\"\"Complete this data analysis workflow:\n",
    "1. Calculate statistics for these test scores: [78, 85, 92, 88, 95, 91, 87]\n",
    "2. Search for information about 'educational assessment'\n",
    "3. Write a report combining the statistics and search results\n",
    "4. Save the report as 'education_analysis.txt'\n",
    "5. Read back the file to confirm it was saved correctly\n",
    "\"\"\"\n",
    "\n",
    "result = react_agent(complex_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "## Real-World Example: Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pipeline_task = \"\"\"Build a data analysis pipeline:\n",
    "1. Calculate statistics for sales data: [1200, 1450, 1100, 1600, 1850, 1400, 1550]\n",
    "2. Calculate the total sum\n",
    "3. Calculate the average\n",
    "4. Create a summary report with:\n",
    "   - Total sales\n",
    "   - Average sale\n",
    "   - Highest sale\n",
    "   - Lowest sale\n",
    "   - Current date\n",
    "5. Save to 'sales_report.txt'\n",
    "\"\"\"\n",
    "\n",
    "result = plan_and_execute_agent(data_pipeline_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "## Agent Performance Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check created reports\n",
    "print(\"\\nCreated Reports:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "workspace = Path(\"./agent_workspace\")\n",
    "if workspace.exists():\n",
    "    reports = list(workspace.glob(\"*.txt\"))\n",
    "    print(f\"Total reports: {len(reports)}\\n\")\n",
    "    \n",
    "    for report in reports:\n",
    "        size = report.stat().st_size\n",
    "        print(f\"  - {report.name} ({size} bytes)\")\n",
    "        \n",
    "        # Show first 100 chars\n",
    "        with open(report, 'r') as f:\n",
    "            preview = f.read(100)\n",
    "        print(f\"    Preview: {preview}...\\n\")\n",
    "else:\n",
    "    print(\"No reports created yet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-27",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. **Custom Workflow**: Design a 5-step workflow using multiple tools\n",
    "2. **Error Recovery**: Test how agents handle tool failures\n",
    "3. **Optimization**: Which pattern is fastest for your use case?\n",
    "4. **Tool Addition**: Add a new tool (e.g., `translate_text`) and test it\n",
    "5. **Model Comparison**: Compare llama3.2:3b vs llama3.1:8b performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here for exercises\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-29",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "✅ **Three agent patterns**: ReAct, Plan-and-Execute, Reflection\n",
    "\n",
    "✅ **ReAct** is fastest for simple tasks\n",
    "\n",
    "✅ **Plan-and-Execute** better for complex workflows\n",
    "\n",
    "✅ **Reflection** improves quality through self-critique\n",
    "\n",
    "✅ **Tool chaining** enables sophisticated workflows\n",
    "\n",
    "✅ **Local models** (llama3) can handle multi-tool tasks\n",
    "\n",
    "## Congratulations!\n",
    "\n",
    "You've completed the Agentic Workflows series! You now know:\n",
    "\n",
    "- MCP protocol fundamentals\n",
    "- Building reusable MCP servers\n",
    "- Three major agent architectures\n",
    "- Complex multi-tool workflows\n",
    "- Using local LLMs for agentic tasks\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Build your own MCP server for a domain you care about\n",
    "- Explore [MCP community servers](https://github.com/modelcontextprotocol/servers)\n",
    "- Try commercial agents (Claude, GPT-4) for comparison\n",
    "- Combine with Notebooks 10-13 for production workflows\n",
    "\n",
    "## Resources\n",
    "\n",
    "- [Model Context Protocol](https://modelcontextprotocol.io/)\n",
    "- [ReAct Paper](https://arxiv.org/abs/2210.03629)\n",
    "- [LangChain Agents](https://python.langchain.com/docs/modules/agents/)\n",
    "- [Ollama Function Calling](https://ollama.com/blog/tool-support)\n",
    "- [MCP Examples](https://github.com/modelcontextprotocol/examples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}