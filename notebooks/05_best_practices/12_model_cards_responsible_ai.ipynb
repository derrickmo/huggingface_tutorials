{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Cards and Responsible AI\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "In this notebook, you will learn:\n",
    "- What model cards are and why they matter\n",
    "- How to read and interpret HuggingFace model cards\n",
    "- Understanding model limitations, biases, and intended use cases\n",
    "- Ethical considerations when deploying AI models\n",
    "- How to evaluate if a model is appropriate for your use case\n",
    "- Responsible AI practices and best practices\n",
    "- System cards for production deployment\n",
    "\n",
    "**This notebook focuses on concepts, not code.** We'll examine real model cards from models used in previous notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "| Requirement | Minimum | Recommended |\n",
    "|------------|---------|-------------|\n",
    "| RAM | 2GB | 4GB |\n",
    "| GPU | Not required | Not required |\n",
    "| Python | 3.8+ | 3.10+ |\n",
    "| Storage | 1GB free | 2GB free |\n",
    "\n",
    "**Recommended**: Complete notebooks 01-10 first to understand the models we'll reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Behaviors\n",
    "\n",
    "When running this notebook, you should observe:\n",
    "\n",
    "**Model Card Fetching**:\n",
    "- Model cards download from HuggingFace Hub\n",
    "- README.md files contain markdown-formatted documentation\n",
    "- Some models have extensive documentation, others are minimal\n",
    "\n",
    "**Card Content**:\n",
    "- Training data sources and sizes\n",
    "- Evaluation metrics and benchmarks\n",
    "- Known limitations and biases\n",
    "- Intended use cases (and out-of-scope uses)\n",
    "- Ethical considerations\n",
    "\n",
    "**Programmatic Access**:\n",
    "- Can fetch model cards via HuggingFace API\n",
    "- Metadata available in JSON format\n",
    "- Tags and task classifications\n",
    "\n",
    "**Common Observations**:\n",
    "- Popular models have comprehensive documentation\n",
    "- Smaller/newer models may have minimal cards\n",
    "- Dataset biases are often documented\n",
    "- Most cards include citation information\n",
    "\n",
    "**Troubleshooting**:\n",
    "- If card fetch fails: Check internet connection\n",
    "- If card is missing: Model may not have documentation (red flag!)\n",
    "- If information is unclear: Check original paper or dataset documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "**Model cards** are documentation that accompanies machine learning models. They provide transparency about:\n",
    "- What the model does\n",
    "- How it was trained\n",
    "- What it's good (and bad) at\n",
    "- Ethical considerations\n",
    "- Appropriate and inappropriate uses\n",
    "\n",
    "Think of model cards as **nutrition labels for AI models** - they help you make informed decisions.\n",
    "\n",
    "**Why model cards matter**:\n",
    "1. **Transparency**: Understand what you're deploying\n",
    "2. **Accountability**: Document model behavior and limitations\n",
    "3. **Safety**: Avoid using models for inappropriate tasks\n",
    "4. **Ethics**: Recognize and mitigate biases\n",
    "5. **Compliance**: Meet regulatory requirements\n",
    "\n",
    "This notebook teaches you to be a **responsible AI practitioner** by critically evaluating models before deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Import libraries\nimport random\nfrom huggingface_hub import HfApi, model_info, hf_hub_download\nfrom transformers import pipeline\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Set seed for reproducibility\nrandom.seed(1103)\n\n# Initialize HuggingFace API\napi = HfApi()\n\nprint(\"✓ Libraries imported successfully\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Anatomy of a Model Card\n",
    "\n",
    "A complete model card typically includes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Essential Components\n",
    "\n",
    "**1. Model Description**\n",
    "- What task does it perform?\n",
    "- What architecture is it based on?\n",
    "- Who created it?\n",
    "\n",
    "**2. Intended Use**\n",
    "- Primary use cases\n",
    "- Supported languages/domains\n",
    "- Known limitations\n",
    "\n",
    "**3. Training Data**\n",
    "- Dataset(s) used\n",
    "- Data size and composition\n",
    "- Preprocessing steps\n",
    "\n",
    "**4. Evaluation**\n",
    "- Benchmarks and metrics\n",
    "- Performance on test sets\n",
    "- Comparison to other models\n",
    "\n",
    "**5. Ethical Considerations**\n",
    "- Known biases\n",
    "- Risks and harms\n",
    "- Recommendations for responsible use\n",
    "\n",
    "**6. Limitations and Biases**\n",
    "- What the model can't do\n",
    "- Edge cases and failure modes\n",
    "- Dataset biases\n",
    "\n",
    "**7. Citation and License**\n",
    "- How to cite the model\n",
    "- Usage license\n",
    "- Links to papers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Fetching a Model Card Programmatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Fetch model card for DistilBERT (used in Notebook 02)\n",
    "model_id = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "\n",
    "# Get model information\n",
    "info = model_info(model_id)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(f\"MODEL INFORMATION: {model_id}\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Task: {info.pipeline_tag}\")\n",
    "print(f\"Model ID: {info.id}\")\n",
    "print(f\"Downloads: {info.downloads:,}\")\n",
    "print(f\"Likes: {info.likes}\")\n",
    "print(f\"Tags: {', '.join(info.tags[:10])}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the actual README (model card)\n",
    "try:\n",
    "    readme_path = hf_hub_download(repo_id=model_id, filename=\"README.md\", repo_type=\"model\")\n",
    "    \n",
    "    with open(readme_path, 'r', encoding='utf-8') as f:\n",
    "        card_content = f.read()\n",
    "    \n",
    "    # Display first 2000 characters\n",
    "    print(\"\\nMODEL CARD PREVIEW:\")\n",
    "    print(\"=\"*70)\n",
    "    print(card_content[:2000])\n",
    "    print(\"\\n... (truncated)\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nFull card is {len(card_content)} characters long\")\n",
    "    print(f\"View online: https://huggingface.co/{model_id}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Could not fetch model card: {e}\")\n",
    "    print(f\"View online: https://huggingface.co/{model_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Examining Real Model Cards\n",
    "\n",
    "Let's examine model cards from models we've used in previous notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Case Study: GPT-2 (Text Generation)\n",
    "\n",
    "**Model**: `gpt2-medium` (Notebook 01)\n",
    "\n",
    "**View card**: https://huggingface.co/gpt2-medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine GPT-2 metadata\n",
    "gpt2_info = model_info(\"gpt2-medium\")\n",
    "\n",
    "print(\"GPT-2 MEDIUM - KEY INFORMATION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Task: {gpt2_info.pipeline_tag}\")\n",
    "print(f\"Downloads: {gpt2_info.downloads:,}\")\n",
    "print(f\"\\nKey Points from Model Card:\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# These are real facts from GPT-2's model card\n",
    "key_points = \"\"\"\n",
    "INTENDED USE:\n",
    "• Research on language models and text generation\n",
    "• Creative writing assistance\n",
    "• NOT intended for factual information generation\n",
    "\n",
    "TRAINING DATA:\n",
    "• WebText dataset (8 million web pages)\n",
    "• English language content from outbound Reddit links\n",
    "• 40GB of text data\n",
    "\n",
    "LIMITATIONS:\n",
    "• May generate biased, offensive, or false content\n",
    "• Reflects biases present in web text\n",
    "• Not fact-checked or filtered for accuracy\n",
    "• Can memorize and reproduce training data\n",
    "\n",
    "BIASES:\n",
    "• Gender biases (occupational stereotypes)\n",
    "• Racial biases (from internet text)\n",
    "• Toxicity (can generate harmful content)\n",
    "• Western/English-centric worldview\n",
    "\n",
    "OUT-OF-SCOPE USES:\n",
    "• Medical, legal, or financial advice\n",
    "• Generating misleading information\n",
    "• Impersonating real people\n",
    "• Automated content creation without disclosure\n",
    "\"\"\"\n",
    "\n",
    "print(key_points)\n",
    "print(\"=\"*70)\n",
    "print(\"\\n⚠️  Critical: GPT-2 can generate harmful content. Always review outputs!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Case Study: DETR (Object Detection)\n",
    "\n",
    "**Model**: `facebook/detr-resnet-50` (Notebook 05)\n",
    "\n",
    "**View card**: https://huggingface.co/facebook/detr-resnet-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detr_info = model_info(\"facebook/detr-resnet-50\")\n",
    "\n",
    "print(\"DETR OBJECT DETECTION - KEY INFORMATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "key_points = \"\"\"\n",
    "INTENDED USE:\n",
    "• Object detection in natural images\n",
    "• Detecting common objects (COCO categories)\n",
    "• Research and prototyping\n",
    "\n",
    "TRAINING DATA:\n",
    "• COCO 2017 dataset (118,000 training images)\n",
    "• 80 object categories\n",
    "• Annotated with bounding boxes\n",
    "\n",
    "PERFORMANCE:\n",
    "• 42.0 AP on COCO val2017\n",
    "• Better on large objects than small objects\n",
    "\n",
    "LIMITATIONS:\n",
    "• Only detects 80 COCO categories (won't detect other objects)\n",
    "• Performance degrades on:\n",
    "  - Very small objects\n",
    "  - Heavily occluded objects\n",
    "  - Objects from unusual viewpoints\n",
    "  - Images very different from COCO (medical, satellite, etc.)\n",
    "• Dataset bias: More common objects detected more accurately\n",
    "\n",
    "BIASES:\n",
    "• COCO dataset is Western-centric (US/Europe images)\n",
    "• Better performance on common objects (person, car) vs rare (toaster)\n",
    "• Struggles with cultural variations (e.g., different chair styles)\n",
    "\n",
    "ETHICAL CONSIDERATIONS:\n",
    "• Can be used for surveillance (privacy concerns)\n",
    "• May misidentify objects in critical applications\n",
    "• Should not be used for security without human review\n",
    "\"\"\"\n",
    "\n",
    "print(key_points)\n",
    "print(\"=\"*70)\n",
    "print(\"\\n⚠️  Don't use object detection for high-stakes decisions without validation!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Case Study: Whisper (Speech Recognition)\n",
    "\n",
    "**Model**: `openai/whisper-small` (Notebook 07)\n",
    "\n",
    "**View card**: https://huggingface.co/openai/whisper-small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whisper_info = model_info(\"openai/whisper-small\")\n",
    "\n",
    "print(\"WHISPER SPEECH RECOGNITION - KEY INFORMATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "key_points = \"\"\"\n",
    "INTENDED USE:\n",
    "• Automatic speech recognition\n",
    "• Multilingual transcription (99 languages)\n",
    "• Audio translation to English\n",
    "\n",
    "TRAINING DATA:\n",
    "• 680,000 hours of multilingual audio\n",
    "• Web-scraped data (YouTube, podcasts, etc.)\n",
    "• Diverse accents, recording conditions, and content types\n",
    "\n",
    "PERFORMANCE:\n",
    "• Near human-level accuracy on LibriSpeech (clean English)\n",
    "• Variable performance across languages\n",
    "• Better on high-resource languages (English, Spanish) vs low-resource\n",
    "\n",
    "LIMITATIONS:\n",
    "• Accuracy varies by:\n",
    "  - Language (English > others)\n",
    "  - Audio quality (clean > noisy)\n",
    "  - Accent (native > non-native)\n",
    "  - Domain (conversational > technical jargon)\n",
    "• May hallucinate (generate text not in audio)\n",
    "• Timestamp accuracy not guaranteed\n",
    "• Struggles with overlapping speech\n",
    "\n",
    "BIASES:\n",
    "• Higher error rates for:\n",
    "  - Non-native English speakers\n",
    "  - Certain accents (African, South Asian)\n",
    "  - Female vs male voices (slight difference)\n",
    "  - Low-resource languages\n",
    "• Reflects biases in web-scraped training data\n",
    "\n",
    "ETHICAL CONSIDERATIONS:\n",
    "• Privacy: Can transcribe private conversations\n",
    "• Consent: Training data may include non-consented audio\n",
    "• Accessibility: Don't rely solely for critical accessibility needs\n",
    "• Hallucinations: May attribute words that weren't spoken\n",
    "\n",
    "OUT-OF-SCOPE USES:\n",
    "• Legal transcripts (hallucinations are unacceptable)\n",
    "• Medical dictation (errors could be harmful)\n",
    "• Surveillance without consent\n",
    "• Speaker identification (not designed for this)\n",
    "\"\"\"\n",
    "\n",
    "print(key_points)\n",
    "print(\"=\"*70)\n",
    "print(\"\\n⚠️  Whisper can hallucinate! Always verify transcripts for critical uses.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Evaluating Model Appropriateness\n",
    "\n",
    "Before using a model, ask these questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 The Model Evaluation Checklist\n",
    "\n",
    "**1. Task Alignment**\n",
    "- [ ] Does the model's intended use match my use case?\n",
    "- [ ] Is my domain similar to the training data?\n",
    "- [ ] Are there out-of-scope uses that apply to me?\n",
    "\n",
    "**2. Performance Requirements**\n",
    "- [ ] Does the model's accuracy meet my needs?\n",
    "- [ ] Have I tested it on representative examples?\n",
    "- [ ] What happens when the model is wrong?\n",
    "\n",
    "**3. Data Compatibility**\n",
    "- [ ] Is my data similar to the training data?\n",
    "- [ ] Are there distribution shifts (different languages, domains, etc.)?\n",
    "- [ ] Does the model support my language/region?\n",
    "\n",
    "**4. Bias and Fairness**\n",
    "- [ ] What biases exist in the model?\n",
    "- [ ] Could these biases harm my users?\n",
    "- [ ] How will I monitor and mitigate biases?\n",
    "\n",
    "**5. Safety and Ethics**\n",
    "- [ ] What are the potential harms?\n",
    "- [ ] Is human review needed?\n",
    "- [ ] Do I have user consent?\n",
    "- [ ] Am I transparent about using AI?\n",
    "\n",
    "**6. Legal and Compliance**\n",
    "- [ ] What's the model's license?\n",
    "- [ ] Can I use it commercially?\n",
    "- [ ] Do I comply with data protection laws (GDPR, etc.)?\n",
    "- [ ] Are there intellectual property concerns?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Example: Should I Use This Model?\n",
    "\n",
    "Let's evaluate a real scenario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario: Building a customer review sentiment analyzer for a global e-commerce site\n",
    "\n",
    "scenario = \"\"\"\n",
    "SCENARIO:\n",
    "You want to automatically classify customer reviews as positive/negative\n",
    "to help prioritize customer service responses.\n",
    "\n",
    "Requirements:\n",
    "• Handle reviews from multiple countries (US, UK, India, Japan)\n",
    "• Process 10,000 reviews/day\n",
    "• Flag negative reviews for human review\n",
    "• Must not miss critical negative reviews (safety-critical product)\n",
    "\"\"\"\n",
    "\n",
    "print(scenario)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EVALUATING: distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "evaluation = \"\"\"\n",
    "✓ GOOD FIT:\n",
    "• Fast inference (meets 10k/day requirement)\n",
    "• Good accuracy on English reviews\n",
    "• Free and commercially usable (Apache 2.0 license)\n",
    "\n",
    "✗ POOR FIT:\n",
    "• Only supports English (fails for Japanese reviews)\n",
    "• Trained on movie reviews (different domain than products)\n",
    "• May have bias toward certain writing styles\n",
    "• No guarantee of catching all critical reviews\n",
    "\n",
    "RECOMMENDATION:\n",
    "⚠️  CONDITIONAL USE:\n",
    "1. Use ONLY for English reviews (add language detection)\n",
    "2. Implement human review for ALL high-confidence negative reviews\n",
    "3. Regularly audit false negatives (missed negative reviews)\n",
    "4. Consider fine-tuning on your product review data\n",
    "5. Add multilingual model for non-English reviews\n",
    "6. Set conservative threshold (flag uncertain cases for review)\n",
    "\n",
    "ALTERNATIVE:\n",
    "Consider: xlm-roberta-base (multilingual) with fine-tuning on\n",
    "product reviews from your actual customer base.\n",
    "\"\"\"\n",
    "\n",
    "print(evaluation)\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Responsible AI Practices\n",
    "\n",
    "Beyond reading model cards, follow these best practices:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Core Principles\n",
    "\n",
    "**1. Transparency**\n",
    "- Disclose when AI is being used\n",
    "- Explain how decisions are made\n",
    "- Document model choice and limitations\n",
    "\n",
    "**2. Fairness**\n",
    "- Test for bias across demographic groups\n",
    "- Monitor performance disparities\n",
    "- Mitigate identified biases\n",
    "\n",
    "**3. Accountability**\n",
    "- Assign responsibility for AI decisions\n",
    "- Implement human oversight\n",
    "- Create appeal/review processes\n",
    "\n",
    "**4. Privacy**\n",
    "- Minimize data collection\n",
    "- Secure user data\n",
    "- Comply with regulations (GDPR, CCPA)\n",
    "\n",
    "**5. Safety**\n",
    "- Test edge cases and failure modes\n",
    "- Implement safety guardrails\n",
    "- Monitor for misuse\n",
    "\n",
    "**6. Reliability**\n",
    "- Validate on diverse test sets\n",
    "- Monitor performance in production\n",
    "- Have fallback mechanisms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Red Flags: When NOT to Deploy\n",
    "\n",
    "**Don't deploy a model if:**\n",
    "\n",
    "❌ **No model card exists** - Lack of transparency is a warning sign\n",
    "\n",
    "❌ **Unknown training data** - You can't assess biases or legal risks\n",
    "\n",
    "❌ **Intended use unclear** - Model might not be designed for your task\n",
    "\n",
    "❌ **High-stakes application without validation** - Medical, legal, financial decisions need extensive testing\n",
    "\n",
    "❌ **Can't handle model errors** - No fallback mechanism for failures\n",
    "\n",
    "❌ **No human oversight** - Critical decisions need human review\n",
    "\n",
    "❌ **Biases affect vulnerable groups** - Documented biases that could harm users\n",
    "\n",
    "❌ **License prohibits your use case** - Legal compliance is non-negotiable\n",
    "\n",
    "❌ **Can't explain decisions to users** - Regulatory requirement in many domains\n",
    "\n",
    "❌ **Performance degrades on your data** - Testing shows poor results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Bias Detection Example\n",
    "\n",
    "Let's test a sentiment model for potential gender bias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sentiment classifier\n",
    "classifier = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "# Test sentences with gendered pronouns\n",
    "test_cases = [\n",
    "    # Occupation stereotypes\n",
    "    (\"He is a great engineer\", \"She is a great engineer\"),\n",
    "    (\"He is an excellent nurse\", \"She is an excellent nurse\"),\n",
    "    (\"He is a talented CEO\", \"She is a talented CEO\"),\n",
    "    \n",
    "    # Emotional expressions\n",
    "    (\"He was very emotional about it\", \"She was very emotional about it\"),\n",
    "    (\"He is assertive\", \"She is assertive\"),\n",
    "    (\"He is so bossy\", \"She is so bossy\"),\n",
    "]\n",
    "\n",
    "print(\"\\nTESTING FOR GENDER BIAS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Sentence':<40} {'Label':<10} {'Score':<10}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for male_sent, female_sent in test_cases:\n",
    "    male_result = classifier(male_sent)[0]\n",
    "    female_result = classifier(female_sent)[0]\n",
    "    \n",
    "    print(f\"{male_sent:<40} {male_result['label']:<10} {male_result['score']:.3f}\")\n",
    "    print(f\"{female_sent:<40} {female_result['label']:<10} {female_result['score']:.3f}\")\n",
    "    \n",
    "    # Flag if labels differ or scores differ significantly\n",
    "    if male_result['label'] != female_result['label']:\n",
    "        print(\"  ⚠️  BIAS DETECTED: Different labels!\")\n",
    "    elif abs(male_result['score'] - female_result['score']) > 0.1:\n",
    "        print(f\"  ⚠️  Score difference: {abs(male_result['score'] - female_result['score']):.3f}\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"\\nNote: This is a simplified bias test. Real bias testing requires:\")\n",
    "print(\"• Large, diverse test sets\")\n",
    "print(\"• Statistical significance testing\")\n",
    "print(\"• Testing across multiple dimensions (race, age, etc.)\")\n",
    "print(\"• Domain-specific evaluation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: System Cards for Production\n",
    "\n",
    "**System cards** document entire AI systems (not just individual models)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 What is a System Card?\n",
    "\n",
    "A **system card** describes the complete AI system, including:\n",
    "- Models used\n",
    "- Data pipelines\n",
    "- Pre/post-processing\n",
    "- Human-in-the-loop components\n",
    "- Monitoring and governance\n",
    "- Deployment context\n",
    "\n",
    "**Example**: A content moderation system might use:\n",
    "- Text classification model (detect toxic content)\n",
    "- Image classification model (detect inappropriate images)\n",
    "- Human reviewers (for borderline cases)\n",
    "- Appeal process (for false positives)\n",
    "- Monitoring dashboard (track performance)\n",
    "\n",
    "The **system card** would document ALL of these components, not just the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 System Card Template\n",
    "\n",
    "```markdown\n",
    "# System Card: [System Name]\n",
    "\n",
    "## System Overview\n",
    "- **Purpose**: What does the system do?\n",
    "- **Users**: Who uses it?\n",
    "- **Deployment context**: Where is it deployed?\n",
    "\n",
    "## System Components\n",
    "- **Models**: List all ML models\n",
    "  - Model A: [purpose, version, model card link]\n",
    "  - Model B: [purpose, version, model card link]\n",
    "- **Data sources**: Input data and origins\n",
    "- **Processing**: Pre/post-processing steps\n",
    "- **Human oversight**: Where humans are involved\n",
    "\n",
    "## Performance\n",
    "- **Metrics**: System-level metrics\n",
    "- **Benchmarks**: Performance on test sets\n",
    "- **Monitoring**: How is performance tracked?\n",
    "\n",
    "## Limitations\n",
    "- **Known failures**: What doesn't work?\n",
    "- **Edge cases**: Difficult scenarios\n",
    "- **Scope**: What's out of scope?\n",
    "\n",
    "## Ethical Considerations\n",
    "- **Biases**: System-level biases\n",
    "- **Harms**: Potential negative impacts\n",
    "- **Mitigations**: How are risks reduced?\n",
    "\n",
    "## Governance\n",
    "- **Ownership**: Who is responsible?\n",
    "- **Review process**: How are decisions audited?\n",
    "- **Updates**: How often is the system updated?\n",
    "- **Incident response**: What happens when things go wrong?\n",
    "\n",
    "## Compliance\n",
    "- **Regulations**: Which laws apply?\n",
    "- **Privacy**: How is data protected?\n",
    "- **Transparency**: What is disclosed to users?\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Example System Card\n",
    "\n",
    "Here's a simplified system card for our hypothetical review analysis system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_card_example = \"\"\"\n",
    "# System Card: Product Review Analysis System\n",
    "Version 1.0 | Last Updated: 2025-01-15\n",
    "\n",
    "## System Overview\n",
    "Purpose: Automatically classify customer reviews and prioritize negative reviews\n",
    "         for customer service team review.\n",
    "Users: Customer service team (internal)\n",
    "Scale: 10,000 reviews/day across 50 product categories\n",
    "\n",
    "## System Components\n",
    "\n",
    "Models:\n",
    "• Language Detection: \"papluca/xlm-roberta-base-language-detection\"\n",
    "• Sentiment (English): \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "• Sentiment (Multilingual): \"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
    "\n",
    "Data Flow:\n",
    "1. Review text → Language detection\n",
    "2. Route to appropriate sentiment model\n",
    "3. Classify sentiment + confidence score\n",
    "4. If negative with >0.7 confidence → flag for human review\n",
    "5. If uncertain (0.4-0.7) → flag for review\n",
    "6. If positive with >0.7 → auto-acknowledge\n",
    "\n",
    "Human Oversight:\n",
    "• All flagged reviews reviewed by customer service team\n",
    "• Weekly audit of 100 random positive classifications\n",
    "• Monthly bias and fairness review\n",
    "\n",
    "## Performance Metrics\n",
    "Target: 90% accuracy on English reviews, 85% on multilingual\n",
    "Current: 88% on English, 82% on multilingual (as of 2025-01-15)\n",
    "\n",
    "False Negative Rate: <5% (missing critical negative reviews)\n",
    "Current: 3.2%\n",
    "\n",
    "Human Review Rate: 25-30% of all reviews\n",
    "Current: 28%\n",
    "\n",
    "## Limitations\n",
    "• Sarcasm detection poor (\"Oh great, another broken product!\")\n",
    "• Struggles with code-switching (mixing languages)\n",
    "• Domain shift: Models trained on social media, not product reviews\n",
    "• Lower accuracy on:\n",
    "  - Technical products (specialized vocabulary)\n",
    "  - Low-resource languages\n",
    "  - Very short reviews (<10 words)\n",
    "\n",
    "## Ethical Considerations\n",
    "\n",
    "Biases:\n",
    "• English reviews processed more accurately than others\n",
    "• May miss culturally-specific expressions of dissatisfaction\n",
    "\n",
    "Mitigations:\n",
    "• Conservative threshold (flag uncertain cases)\n",
    "• Mandatory human review of all flagged reviews\n",
    "• Regular bias audits across language groups\n",
    "• Continuous fine-tuning on misclassified examples\n",
    "\n",
    "Privacy:\n",
    "• Reviews contain PII (names, addresses in text)\n",
    "• PII redacted before model processing\n",
    "• Reviewers see full text (with PII)\n",
    "\n",
    "## Governance\n",
    "\n",
    "Ownership: Customer Experience Team\n",
    "Technical Lead: AI/ML Team\n",
    "\n",
    "Review Process:\n",
    "• Weekly performance review\n",
    "• Monthly fairness audit\n",
    "• Quarterly model updates\n",
    "\n",
    "Incident Response:\n",
    "• Critical customer issue missed → Immediate review of case\n",
    "• Pattern of misclassification → Temporary increased human review\n",
    "• Model downtime → Fallback to 100% human review\n",
    "\n",
    "## Compliance\n",
    "\n",
    "Privacy: GDPR-compliant (data retention, right to explanation)\n",
    "Transparency: Customers informed of automated processing\n",
    "Appeals: Customers can request human review of auto-responses\n",
    "\n",
    "## Change Log\n",
    "- 2025-01-15: v1.0 Initial deployment\n",
    "\"\"\"\n",
    "\n",
    "print(system_card_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Model Card Comparison Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(model_ids):\n",
    "    \"\"\"\n",
    "    Compare multiple models side-by-side.\n",
    "    \"\"\"\n",
    "    print(\"\\nMODEL COMPARISON\")\n",
    "    print(\"=\"*100)\n",
    "    print(f\"{'Model':<50} {'Task':<20} {'Downloads':<15} {'Likes'}\")\n",
    "    print(\"-\"*100)\n",
    "    \n",
    "    for model_id in model_ids:\n",
    "        try:\n",
    "            info = model_info(model_id)\n",
    "            print(f\"{model_id:<50} {info.pipeline_tag or 'N/A':<20} {info.downloads or 0:<15,} {info.likes or 0}\")\n",
    "        except Exception as e:\n",
    "            print(f\"{model_id:<50} {'ERROR':<20} {'-':<15} {'-'}\")\n",
    "    \n",
    "    print(\"=\"*100)\n",
    "\n",
    "# Example: Compare sentiment analysis models\n",
    "sentiment_models = [\n",
    "    \"distilbert-base-uncased-finetuned-sst-2-english\",\n",
    "    \"cardiffnlp/twitter-roberta-base-sentiment\",\n",
    "    \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "]\n",
    "\n",
    "compare_models(sentiment_models)\n",
    "\n",
    "print(\"\\nQuestions to ask when comparing:\")\n",
    "print(\"• Which has better documentation (model card)?\")\n",
    "print(\"• Which is more popular (downloads/likes)?\")\n",
    "print(\"• Which supports my languages?\")\n",
    "print(\"• Which is more recently updated?\")\n",
    "print(\"• Which has better performance on my domain?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. **Model Card Deep Dive**: Choose a model from notebooks 01-10. Read its full model card. Create a one-page summary covering: intended use, limitations, biases, and whether you'd use it in production.\n",
    "\n",
    "2. **Bias Testing**: Pick a text classification model and design 10 test cases to check for gender, racial, or other biases. Run the tests and document findings.\n",
    "\n",
    "3. **Evaluation Checklist**: For a hypothetical project (e.g., medical chatbot, resume screener, content moderator), fill out the Model Evaluation Checklist from section 3.1. Would you deploy? Why or why not?\n",
    "\n",
    "4. **System Card**: Design a simple AI system (e.g., spam filter, product recommender). Write a system card following the template in section 5.2.\n",
    "\n",
    "5. **Red Flags**: Find 3 models on HuggingFace Hub that have poor or missing model cards. Document why these are concerning and what information is missing.\n",
    "\n",
    "6. **Fairness Audit**: Pick a model and define 3 demographic groups (e.g., age ranges, languages, genders). Design tests to measure performance disparities across these groups.\n",
    "\n",
    "**Bonus Challenge**: Find a model with an excellent model card and one with a poor/missing card for the same task. Write a comparison explaining why documentation matters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "**Model Cards**:\n",
    "- Essential documentation for ML models\n",
    "- Cover intended use, limitations, biases, and ethical considerations\n",
    "- ALWAYS read before deploying a model\n",
    "\n",
    "**Responsible AI**:\n",
    "- Transparency, fairness, accountability, privacy, safety, reliability\n",
    "- Test for biases before deployment\n",
    "- Implement human oversight for high-stakes decisions\n",
    "\n",
    "**Evaluation**:\n",
    "- Use the Model Evaluation Checklist\n",
    "- Test on YOUR data, not just benchmarks\n",
    "- Know when NOT to deploy\n",
    "\n",
    "**System Cards**:\n",
    "- Document entire AI systems, not just models\n",
    "- Include governance and incident response\n",
    "- Essential for production deployments\n",
    "\n",
    "**Red Flags**:\n",
    "- Missing model cards\n",
    "- Unknown training data\n",
    "- High-stakes use without validation\n",
    "- Biases that harm vulnerable groups\n",
    "\n",
    "**Best Practice**: If you can't explain how your model works, what its limitations are, and how you'll handle failures - **don't deploy it**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "**Model Card Resources**:\n",
    "- [Model Cards for Model Reporting (Original Paper)](https://arxiv.org/abs/1810.03993)\n",
    "- [HuggingFace Model Cards Guide](https://huggingface.co/docs/hub/model-cards)\n",
    "- [System Cards (OpenAI)](https://openai.com/research/gpt-4-system-card)\n",
    "\n",
    "**Responsible AI Frameworks**:\n",
    "- [Google's Responsible AI Practices](https://ai.google/responsibilities/responsible-ai-practices/)\n",
    "- [Microsoft's Responsible AI Principles](https://www.microsoft.com/en-us/ai/responsible-ai)\n",
    "- [NIST AI Risk Management Framework](https://www.nist.gov/itl/ai-risk-management-framework)\n",
    "\n",
    "**Bias and Fairness**:\n",
    "- [AI Fairness 360 (IBM)](https://aif360.mybluemix.net/)\n",
    "- [What-If Tool (Google)](https://pair-code.github.io/what-if-tool/)\n",
    "- [Fairlearn (Microsoft)](https://fairlearn.org/)\n",
    "\n",
    "**Regulations**:\n",
    "- [EU AI Act](https://artificialintelligenceact.eu/)\n",
    "- [GDPR (Data Protection)](https://gdpr.eu/)\n",
    "- [California CCPA](https://oag.ca.gov/privacy/ccpa)\n",
    "\n",
    "**Academic Resources**:\n",
    "- [ACM Conference on Fairness, Accountability, and Transparency (FAccT)](https://facctconference.org/)\n",
    "- [Partnership on AI](https://partnershiponai.org/)\n",
    "\n",
    "**Next Steps**:\n",
    "- Notebook 13: Fine-tuning with LoRA (Text Generation)\n",
    "- Apply responsible AI principles when fine-tuning your own models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}